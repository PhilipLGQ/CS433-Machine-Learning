{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import files to use in preprocessing and machine learning\n",
    "from implementations import *\n",
    "from proj1_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Download train data and supply path here \n",
    "DATA_TRAIN_PATH = 'data_aicrowd/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "(250000, 30)\n",
      "(250000,)\n"
     ]
    }
   ],
   "source": [
    "# Check the array shape of y, tX, and ids\n",
    "print(y.shape)\n",
    "print(tX.shape)\n",
    "print(ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In observing the original training data, we found out that there exists missing data all over tX. The missing data are represented as value -999. Considering that these columns are critical in model training, we cannot simply delete these rows with -999 values. Therefore, we need to process the original training set before model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we check the columns of tX to obtain an overview of missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0 has 15.2456% percentage of missing values\n",
      "P(y = 1|x having -999) = 7.438%\n",
      "P(y = -1|x having -999) = 92.562% \n",
      "\n",
      "Column 4 has 70.9828% percentage of missing values\n",
      "P(y = 1|x having -999) = 29.980%\n",
      "P(y = -1|x having -999) = 70.020% \n",
      "\n",
      "Column 5 has 70.9828% percentage of missing values\n",
      "P(y = 1|x having -999) = 29.980%\n",
      "P(y = -1|x having -999) = 70.020% \n",
      "\n",
      "Column 6 has 70.9828% percentage of missing values\n",
      "P(y = 1|x having -999) = 29.980%\n",
      "P(y = -1|x having -999) = 70.020% \n",
      "\n",
      "Column 12 has 70.9828% percentage of missing values\n",
      "P(y = 1|x having -999) = 29.980%\n",
      "P(y = -1|x having -999) = 70.020% \n",
      "\n",
      "Column 23 has 39.9652% percentage of missing values\n",
      "P(y = 1|x having -999) = 25.514%\n",
      "P(y = -1|x having -999) = 74.486% \n",
      "\n",
      "Column 24 has 39.9652% percentage of missing values\n",
      "P(y = 1|x having -999) = 25.514%\n",
      "P(y = -1|x having -999) = 74.486% \n",
      "\n",
      "Column 25 has 39.9652% percentage of missing values\n",
      "P(y = 1|x having -999) = 25.514%\n",
      "P(y = -1|x having -999) = 74.486% \n",
      "\n",
      "Column 26 has 70.9828% percentage of missing values\n",
      "P(y = 1|x having -999) = 29.980%\n",
      "P(y = -1|x having -999) = 70.020% \n",
      "\n",
      "Column 27 has 70.9828% percentage of missing values\n",
      "P(y = 1|x having -999) = 29.980%\n",
      "P(y = -1|x having -999) = 70.020% \n",
      "\n",
      "Column 28 has 70.9828% percentage of missing values\n",
      "P(y = 1|x having -999) = 29.980%\n",
      "P(y = -1|x having -999) = 70.020% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check whether the missing values are associated with the classification result\n",
    "for col in range(tX.shape[1]):\n",
    "    tX_T = np.transpose(tX)\n",
    "    \n",
    "    null = (tx_T[col] == -999)\n",
    "    null_s = np.logical_and(y >= 0, null)\n",
    "    null_b = np.logical_and(y < 0, null)\n",
    "    \n",
    "    tX_null = tX[null]\n",
    "    tX_null_s = tX[null_s]\n",
    "    tX_null_b = tX[null_b]\n",
    "    \n",
    "    if (tX_null.shape[0] > 0):\n",
    "        # Print the percentage of column 'col' having a -999 (missing) value\n",
    "        print('Column', col, 'has {}% percentage of missing values'.format(tX_null.shape[0] * 100 / tX.shape[0]))\n",
    "\n",
    "        # Print the conditional probability of P(y = 1|x having -999)\n",
    "        print('P(y = 1|x having -999) = {:.3f}%'.format(tX_null_s.shape[0] * 100 / tX_null.shape[0]))\n",
    "        \n",
    "        # Print the conditional probability of P(y = -1|x having -999)\n",
    "        print('P(y = -1|x having -999) = {:.3f}% \\n'.format(tX_null_b.shape[0] * 100 / tX_null.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 11 columns contains at least one -999 (missing value). Now we check whether some of the missing values are dependent on the column named 'PRI_jet_num' (column No. 23), since 'PRI_jet_num' has a discrete value range {0, 1, 2, 3} and our observation on the beginning data rows showed a dependency of some missing values to the value of 'PRI_jet_num' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of rows for different PRI_jet_num: 250000 \n",
      "\n",
      "PRI_jet_num = 0 No. of columns having -999 (a missing value):[10, 11]\n",
      "PRI_jet_num = 1 No. of columns having -999 (a missing value):[8, 7]\n",
      "PRI_jet_num = 2 No. of columns having -999 (a missing value):[0, 1]\n",
      "PRI_jet_num = 3 No. of columns having -999 (a missing value):[0, 1]\n"
     ]
    }
   ],
   "source": [
    "PRI_jet_range = [i for i in range(0, 4)]\n",
    "PRI_jet_sum = []\n",
    "PRI_jet_null = []\n",
    "\n",
    "for value in PRI_jet_range:\n",
    "    tX_PRI = tX[tX[:, 22] == value]\n",
    "    \n",
    "    # Append values of row numbers for different PRI_jet_num, finally sum up to see whether it equals to the length of tX\n",
    "    PRI_jet_sum.append(len(tX_PRI))\n",
    "    \n",
    "    # Count the number of missing columns corresponding to different PRI_jet_num values\n",
    "    PRI_jet_keys = []\n",
    "    for i in range (len(tX_PRI)):\n",
    "        tX_null_cols = np.count_nonzero(tX_PRI[i] == -999, axis = 0)\n",
    "        PRI_jet_keys.append(tX_null_cols)\n",
    "    \n",
    "    PRI_jet_null.append(list(set(PRI_jet_keys)))\n",
    "\n",
    "    \n",
    "print(\"Sum of rows for different PRI_jet_num: {} \\n\".format(sum(PRI_jet_sum)))\n",
    "\n",
    "for i in range(4):\n",
    "    print(\"PRI_jet_num =\", PRI_jet_range[i], \"No. of columns having -999 (a missing value):{}\".format(PRI_jet_null[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analysis showed that one column with -999 (missing value) is independent of the column 'PRI_jet_num', we check the original training set and we can easily find out that the first tX column 'DER_mass_MMC' is independent of 'PRI_jet_num'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data analysis above, we conduct the following method to pre-process the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models for different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
